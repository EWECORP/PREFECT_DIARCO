name: dmz_diarco_flows
prefect-version: 3.4.0

pull:
- prefect.deployments.steps.set_working_directory:
    directory: E:/ETL/ETL_DIARCO

deployments:
  - name: publicar_oc_precarga
    entrypoint: scripts/pull/flujo_pull_PRECARGA_OC.py:precargar_OC_connexa
    description: "Publica las OC en estado 90 desde PostgreSQL hacia SQL Server"
    tags: ["pull", "oc", "precarga"]
    work_pool:
      name: dmz-diarco
      work_queue_name: pull-connexa
    schedule:
      cron: "*/10 8-17 * * 1-5"
      timezone: "America/Argentina/Buenos_Aires"
    parameters: {}

  - name: replicar_dmz_lotes
    entrypoint: scripts/repl/flujo_replicar_DMZ_en_LOTES.py:sync_dmz_optimizado
    description: "Obtiene actualizaciones de los datos LEGACY en la DMZ (CDC)"
    tags: ["repl", "dmz", "datos"]
    work_pool:
      name: dmz-diarco
      work_queue_name: replicas-dmz
    schedule:
      cron:  "0 6 * * *"  # Todos los días a las 6 AM  
      timezone: "America/Argentina/Buenos_Aires"
    parameters: {}

  - name: replicar_OC_dmz
    entrypoint: scripts/repl/flujo_replicar_OC_en_dmz.py:flujo_replicacion_oc
    description: "Actualizar dasot de las OC en la DMZ (CDC)"
    tags: ["repl", "dmz", "datos"]
    work_pool:
      name: dmz-diarco
      work_queue_name: replicas-dmz
    schedule:
      cron:  "0 6 * * *"  # Todos los días a las 6 AM  
      timezone: "America/Argentina/Buenos_Aires"
    parameters: {}

  - name: Push_datos_para_FORECAST
    entrypoint: scripts/push/flujo_push_datos_forecast.py:forecast_flow
    description: "Carga Diaria de Datos de proveedores habilitados"
    tags: ["push", "forecast", "datos"]
    work_pool:
      name: dmz-diarco
      work_queue_name: push-forecast
    schedule:
      cron:  "0 7 * * *"  # Todos los días a las 6 AM  
      timezone: "America/Argentina/Buenos_Aires"
    parameters: {}

  - name: enviar_tablas_sftp
    entrypoint: scripts/send/exportar_tabla_sqlserver_sftp.py:exportar_tabla_sqlserver_sftp
    description: "Envío parametrizado de tablas desde SQL Server a PostgreSQL vía SFTP"
    tags: ["pipeline", "replicacion", "datos"]
    work_pool:
      name: dmz-diarco
      work_queue_name: default
    parameters: {}  # Se pasan al ejecutar deployment manualmente

  - name: flujo_maestro_replicacion
    entrypoint: scripts/maestro/flujo_maestro_replica_datos.py:flujo_maestro
    description: "Orquestador maestro que exporta e importa tablas entre SQL Server y PostgreSQL"
    tags: ["maestro", "replicacion", "pipeline"]
    work_pool:
      name: dmz-diarco
      work_queue_name: default
    parameters: {} # Se pasan al ejecutar deployment manualmente